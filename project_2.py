import gradio as gr
from ultralytics import YOLO
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import numpy as np
import cv2
import math
import scipy.fftpack
import pandas as pd

# Load model ƒë√£ train
model = YOLO("runs/detect/train4/weights/best.pt")

def Butterworth_Highpass_Filter(im_1):
    c = scipy.fftpack.fft2(im_1)
    d = scipy.fftpack.fftshift(c)
    M, N = d.shape
    H = np.ones((M, N))
    center1 = M / 2
    center2 = N / 2
    d_0 = 30.0  # b√°n k√≠nh c·∫Øt
    t1 = 1  # b·∫≠c c·ªßa b·ªô l·ªçc

    for i in range(M):
        for j in range(N):
            r = math.sqrt((i - center1) ** 2 + (j - center2) ** 2)
            H[i, j] = 1 - 1 / (1 + (r / d_0) ** (2 * t1))

    con = d * H
    e = abs(scipy.fftpack.ifft2(scipy.fftpack.ifftshift(con)))
    e = (e - np.min(e)) / (np.max(e) - np.min(e)) * 255
    return e.astype(np.uint8)

def Butterworth_Highpass_Color(image):
    img_cv = np.array(image)
    lab = cv2.cvtColor(img_cv, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)

    l_filtered = butterworth_filter(l)
    l_sharpened = cv2.addWeighted(l, 1.0, l_filtered, 1.0, 0)  # tƒÉng r√µ
    merged = cv2.merge((l_sharpened, a, b))
    rgb_result = cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)
    return Image.fromarray(rgb_result)

def butterworth_filter(im_1, d_0=30.0, t1=1):
    M, N = im_1.shape
    u = np.arange(M) - M // 2
    v = np.arange(N) - N // 2
    V, U = np.meshgrid(v, u)
    D = np.sqrt(U**2 + V**2)
    H = 1 - 1 / (1 + (D / d_0) ** (2 * t1))

    F = scipy.fftpack.fftshift(scipy.fftpack.fft2(im_1))
    G = H * F
    g = np.abs(scipy.fftpack.ifft2(scipy.fftpack.ifftshift(G)))
    g = np.clip((g - np.min(g)) / (np.max(g) - np.min(g)) * 255, 0, 255)
    return g.astype(np.uint8)

# ƒê·ªçc d·ªØ li·ªáu t·ª´ file Excel ch·ªâ 1 l·∫ßn
df_dinhduong = pd.read_excel("DinhDuong.xlsx")
df_congdung = pd.read_excel("CongDung.xlsx")
def lay_thong_tin_excel(ten, loai):
    ten = ten.strip().lower()
    try:
        if loai == "C√¥ng d·ª•ng":
            for _, row in df_congdung.iterrows():
                if row["Qu·∫£"].strip().lower() in ten:
                    return row["C√¥ng d·ª•ng"]
        elif loai == "Dinh d∆∞·ª°ng":
            for _, row in df_dinhduong.iterrows():
                if row["Qu·∫£"].strip().lower() in ten:
                    return row["Dinh d∆∞·ª°ng"]
    except Exception as e:
        print("‚ùå L·ªói x·ª≠ l√Ω ·∫£nh:", e)
        return [], []



def hien_thong_tin_excel(ten, mode, loai_thong_tin):
    if mode == "lam_ro_doi_tuong" and ten.strip():
        return gr.update(value=lay_thong_tin_excel(ten, loai_thong_tin), visible=True)
    else:
        return gr.update(visible=False)


# H√†m x·ª≠ l√Ω ·∫£nh
def xu_ly(images, mode, loai_trai_cay, butter_option, ten):

    if not images:
        return [], []

    all_images = []
    counts = {}
    for img_file in images:
        original_img = Image.open(img_file.name).convert("RGB")

        names = model.names
        results = model.predict(original_img, conf=0.25, device="mps")[0]

        try:
            font = ImageFont.truetype("arial.ttf", size=32)
        except:
            font = ImageFont.truetype("DejaVuSans.ttf", size=32)

        # === CH·∫æ ƒê·ªò 1: L√†m r√µ ƒë·ªëi t∆∞·ª£ng ===
        if mode == "lam_ro_doi_tuong":
            blurred = original_img.filter(ImageFilter.GaussianBlur(radius=5))
            img = blurred.copy()
            draw = ImageDraw.Draw(img)
        # === CH·∫æ ƒê·ªò 2: L√†m r√µ ·∫£nh to√†n b·ªô b·∫±ng CLAHE ===
        elif mode == "lam_ro_anh":
            # Chuy·ªÉn PIL -> OpenCV ƒë·ªÉ x·ª≠ l√Ω CLAHE
            img_cv = np.array(original_img)
            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR)

            # CLAHE tr√™n k√™nh L trong LAB
            lab = cv2.cvtColor(img_cv, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            cl = clahe.apply(l)
            merged = cv2.merge((cl, a, b))
            enhanced_bgr = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)
            enhanced_rgb = cv2.cvtColor(enhanced_bgr, cv2.COLOR_BGR2RGB)

            img = Image.fromarray(enhanced_rgb)
            draw = ImageDraw.Draw(img)
        elif mode == "butterworth":
            if butter_option == "Chuy·ªÉn ·∫£nh x√°m":
                gray = original_img.convert("L")
                filtered = Butterworth_Highpass_Filter(np.array(gray))
                combined = cv2.addWeighted(np.array(gray), 0.7, filtered, 1.2, 0)
                img = Image.fromarray(combined).convert("RGB")

            else:
                img = Butterworth_Highpass_Color(original_img)
            draw = ImageDraw.Draw(img)


        # === Tr∆∞·ªùng h·ª£p kh√¥ng r√µ ===
        else:
            img = original_img.copy()
            draw = ImageDraw.Draw(img)

        # Duy·ªát qua k·∫øt qu·∫£ nh·∫≠n di·ªán
        for box in results.boxes:
            cls_id = int(box.cls.item())
            name = names[cls_id]
            conf = float(box.conf.item())
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())

            counts[name] = counts.get(name, 0) + 1

            if mode == "lam_ro_doi_tuong" :
                if loai_trai_cay.lower() in name.lower():
                    roi = original_img.crop((x1, y1, x2, y2))
                    roi = roi.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))
                    img.paste(roi, (x1, y1))
                    draw.rectangle([x1, y1, x2, y2], outline="green", width=3)
                    draw.text((x1, max(y1 - 35, 0)), f"{name} {conf:.2f}", fill="green", font=font)
            else:
                draw.rectangle([x1, y1, x2, y2], outline="green", width=3)
                draw.text((x1, max(y1 - 35, 0)), f"{name} {conf:.2f}", fill="green", font=font)
            
            
        all_images.append(img)

    bang = [[k, v] for k, v in counts.items()]
    return all_images, bang

# Giao di·ªán Gradio
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("## üçé ·ª®ng d·ª•ng Nh·∫≠n Di·ªán & Ph√¢n Lo·∫°i Tr√°i C√¢y")

    with gr.Row(equal_height=True):
        with gr.Column(scale=3):
            gr.Markdown("### üìÅ T·∫£i l√™n ·∫£nh")
            images_input = gr.Files(label="Ch·ªçn 1 ho·∫∑c nhi·ªÅu ·∫£nh", file_types=["image"], file_count="multiple")
        with gr.Column(scale=2):
            gr.Markdown("### üìä K·∫øt qu·∫£ ph√¢n lo·∫°i")
            nut_phan_loai = gr.Button("Ph√¢n lo·∫°i", variant="primary")
            bang_phan_loai = gr.Dataframe(headers=["T√™n", "S·ªë l∆∞·ª£ng"], interactive=False)

    gr.Markdown("### ‚öôÔ∏è Ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω")
    with gr.Row():
        with gr.Column():
            radio_mode = gr.Radio(
                choices=[
                    ("L√†m r√µ ·∫£nh l·ªõn", "lam_ro_anh"),
                    ("L√†m r√µ ƒë·ªëi t∆∞·ª£ng", "lam_ro_doi_tuong"),
                    ("B·ªô l·ªçc th√¥ng cao Butterworth", "butterworth")
                ],
                label="Ch·∫ø ƒë·ªô", value=None, interactive=True
            )

        with gr.Column():
            ten_loai = gr.Textbox(label="Nh·∫≠p t√™n tr√°i c√¢y c·∫ßn l√†m r√µ ƒë·ªëi t∆∞·ª£ng", visible=False)
            butter_mode = gr.Radio(
                choices=["Gi·ªØ m√†u g·ªëc", "Chuy·ªÉn ·∫£nh x√°m"],
                label="Ch·∫ø ƒë·ªô m√†u cho Butterworth",
                value="Gi·ªØ m√†u g·ªëc",
                visible=False
            )

    nut_enter = gr.Button("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω")

    gr.Markdown("### K·∫øt qu·∫£ x·ª≠ l√Ω ")
    with gr.Row():
        with gr.Column(scale=3):
            ket_qua_anh = gr.Gallery(
                label="·∫¢nh sau x·ª≠ l√Ω",
                show_label=False,
                columns="auto",
                object_fit="contain",
                height="auto",
                preview=True
            )
        with gr.Column(scale=2):
            chon_thong_tin = gr.Radio(
                choices=["C√¥ng d·ª•ng", "Dinh d∆∞·ª°ng"],
                value="C√¥ng d·ª•ng",
                label="Ch·ªçn th√¥ng tin c·∫ßn hi·ªÉn th·ªã",
            )
            thong_tin_output = gr.Textbox(
                label="Th√¥ng tin chi ti·∫øt",
                interactive=False,
                visible=False,
                lines=10,
            )

    # ================= S·ª± ki·ªán ==================
    def hien_textbox(mode):
        return (
            gr.update(visible=(mode == "lam_ro_doi_tuong")),
            gr.update(visible=(mode == "butterworth"))
        )

    radio_mode.change(hien_textbox, inputs=radio_mode, outputs=[ten_loai, butter_mode])
    ten_loai.change(fn=hien_thong_tin_excel, inputs=[ten_loai, radio_mode, chon_thong_tin], outputs=thong_tin_output)
    chon_thong_tin.change(fn=hien_thong_tin_excel, inputs=[ten_loai, radio_mode, chon_thong_tin], outputs=thong_tin_output)
    nut_enter.click(fn=xu_ly, inputs=[images_input, radio_mode, ten_loai, butter_mode], outputs=[ket_qua_anh, bang_phan_loai])
    nut_phan_loai.click(fn=xu_ly, inputs=[images_input, radio_mode, ten_loai, butter_mode], outputs=[ket_qua_anh, bang_phan_loai])

# Ch·∫°y ·ª©ng d·ª•ng
demo.launch(share=True)
gr.close_all()